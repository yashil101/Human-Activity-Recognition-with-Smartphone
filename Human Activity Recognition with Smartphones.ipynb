{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The objective of this project is to classify the activities of a subject based on the readings embedded inertial sensors in a waist mounted smartphone. The original dataset was taken for Kaggle website under the name \"Human Activity Recognition with Smartphones\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Description\n",
    "The dataset was prepared by 30 volunteers who performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) while wearing a smartphone with embedded accelerometer amd gyroscope. The sensors captured 2-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. Also, it is specified in the dataset description that the sensor signals were pre-processed by applying noise filters and then sampled in fixed-width sliding window of 2.56 sec and 50% overlap(128 readings/window). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Information\n",
    "-->Triaxial acceleration from accelerometer                         \n",
    "-->Triaxial angular velocity from gyroscope                         \n",
    "-->A 561-feature vector with time and frequency domain variables     \n",
    "-->Its activity label                                               \n",
    "-->An human identifier of subject who carried out the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start by importing relevant libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train=pd.read_csv('train data Human Activity Recognition with Smartphones.csv')\n",
    "test=pd.read_csv('test data Human Activity Recognition with Smartphones.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some top rows of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>0.217424</td>\n",
       "      <td>-0.022700</td>\n",
       "      <td>-0.106453</td>\n",
       "      <td>-0.975585</td>\n",
       "      <td>-0.950248</td>\n",
       "      <td>-0.983110</td>\n",
       "      <td>-0.976929</td>\n",
       "      <td>-0.967475</td>\n",
       "      <td>-0.985013</td>\n",
       "      <td>-0.943272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.625542</td>\n",
       "      <td>-0.047591</td>\n",
       "      <td>0.294363</td>\n",
       "      <td>0.371649</td>\n",
       "      <td>0.603734</td>\n",
       "      <td>0.822001</td>\n",
       "      <td>-0.470098</td>\n",
       "      <td>-0.501469</td>\n",
       "      <td>19</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.017020</td>\n",
       "      <td>-0.116223</td>\n",
       "      <td>-0.995603</td>\n",
       "      <td>-0.983865</td>\n",
       "      <td>-0.987185</td>\n",
       "      <td>-0.995962</td>\n",
       "      <td>-0.981904</td>\n",
       "      <td>-0.986120</td>\n",
       "      <td>-0.942257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.834985</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>0.116185</td>\n",
       "      <td>0.539752</td>\n",
       "      <td>0.794508</td>\n",
       "      <td>-0.667936</td>\n",
       "      <td>0.219258</td>\n",
       "      <td>0.219253</td>\n",
       "      <td>17</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>0.234235</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>-0.099005</td>\n",
       "      <td>-0.987626</td>\n",
       "      <td>-0.992428</td>\n",
       "      <td>-0.994599</td>\n",
       "      <td>-0.987766</td>\n",
       "      <td>-0.992376</td>\n",
       "      <td>-0.994516</td>\n",
       "      <td>-0.944877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829668</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>0.057465</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>-0.550627</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>0.423776</td>\n",
       "      <td>-0.779215</td>\n",
       "      <td>16</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>0.276778</td>\n",
       "      <td>-0.015506</td>\n",
       "      <td>-0.112290</td>\n",
       "      <td>-0.994860</td>\n",
       "      <td>-0.990906</td>\n",
       "      <td>-0.960534</td>\n",
       "      <td>-0.995527</td>\n",
       "      <td>-0.991223</td>\n",
       "      <td>-0.956639</td>\n",
       "      <td>-0.939066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358486</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.430711</td>\n",
       "      <td>-0.348322</td>\n",
       "      <td>-0.876278</td>\n",
       "      <td>0.057382</td>\n",
       "      <td>0.099142</td>\n",
       "      <td>23</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>0.262955</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>-0.031551</td>\n",
       "      <td>0.187343</td>\n",
       "      <td>0.199283</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>0.145770</td>\n",
       "      <td>0.144106</td>\n",
       "      <td>-0.012666</td>\n",
       "      <td>0.532282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400709</td>\n",
       "      <td>0.267329</td>\n",
       "      <td>-0.806729</td>\n",
       "      <td>0.525317</td>\n",
       "      <td>-0.547566</td>\n",
       "      <td>-0.633226</td>\n",
       "      <td>0.319721</td>\n",
       "      <td>0.141660</td>\n",
       "      <td>21</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>0.199453</td>\n",
       "      <td>-0.059948</td>\n",
       "      <td>-0.091760</td>\n",
       "      <td>-0.052589</td>\n",
       "      <td>0.365935</td>\n",
       "      <td>0.440688</td>\n",
       "      <td>-0.204273</td>\n",
       "      <td>0.150769</td>\n",
       "      <td>0.341375</td>\n",
       "      <td>0.450127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822773</td>\n",
       "      <td>0.274326</td>\n",
       "      <td>-0.703220</td>\n",
       "      <td>0.499672</td>\n",
       "      <td>-0.669544</td>\n",
       "      <td>-0.572030</td>\n",
       "      <td>0.257497</td>\n",
       "      <td>0.272840</td>\n",
       "      <td>14</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.274678</td>\n",
       "      <td>-0.023188</td>\n",
       "      <td>-0.124038</td>\n",
       "      <td>-0.986829</td>\n",
       "      <td>-0.896585</td>\n",
       "      <td>-0.949241</td>\n",
       "      <td>-0.988640</td>\n",
       "      <td>-0.905424</td>\n",
       "      <td>-0.949307</td>\n",
       "      <td>-0.924255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559741</td>\n",
       "      <td>0.036589</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>-0.622251</td>\n",
       "      <td>-0.746405</td>\n",
       "      <td>-0.723051</td>\n",
       "      <td>0.275768</td>\n",
       "      <td>-0.054909</td>\n",
       "      <td>6</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>0.285042</td>\n",
       "      <td>-0.014604</td>\n",
       "      <td>-0.098389</td>\n",
       "      <td>-0.981022</td>\n",
       "      <td>-0.941819</td>\n",
       "      <td>-0.969614</td>\n",
       "      <td>-0.983827</td>\n",
       "      <td>-0.941344</td>\n",
       "      <td>-0.970939</td>\n",
       "      <td>-0.915560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.512113</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.285030</td>\n",
       "      <td>-0.373395</td>\n",
       "      <td>-0.199334</td>\n",
       "      <td>-0.572743</td>\n",
       "      <td>0.176423</td>\n",
       "      <td>0.313674</td>\n",
       "      <td>14</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>0.231026</td>\n",
       "      <td>-0.018501</td>\n",
       "      <td>-0.085397</td>\n",
       "      <td>-0.647512</td>\n",
       "      <td>-0.226758</td>\n",
       "      <td>-0.464132</td>\n",
       "      <td>-0.684126</td>\n",
       "      <td>-0.211773</td>\n",
       "      <td>-0.465463</td>\n",
       "      <td>-0.526001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302043</td>\n",
       "      <td>0.398029</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>0.766658</td>\n",
       "      <td>-0.813525</td>\n",
       "      <td>-0.698809</td>\n",
       "      <td>0.174313</td>\n",
       "      <td>-0.183912</td>\n",
       "      <td>25</td>\n",
       "      <td>WALKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>0.247617</td>\n",
       "      <td>-0.025411</td>\n",
       "      <td>-0.098561</td>\n",
       "      <td>-0.985436</td>\n",
       "      <td>-0.993529</td>\n",
       "      <td>-0.986809</td>\n",
       "      <td>-0.986160</td>\n",
       "      <td>-0.992939</td>\n",
       "      <td>-0.985661</td>\n",
       "      <td>-0.938357</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517001</td>\n",
       "      <td>-0.034842</td>\n",
       "      <td>0.692982</td>\n",
       "      <td>0.378813</td>\n",
       "      <td>0.195420</td>\n",
       "      <td>0.548939</td>\n",
       "      <td>-0.247938</td>\n",
       "      <td>-0.767568</td>\n",
       "      <td>23</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "3900           0.217424          -0.022700          -0.106453   \n",
       "3249           0.272708          -0.017020          -0.116223   \n",
       "3133           0.234235          -0.010039          -0.099005   \n",
       "4748           0.276778          -0.015506          -0.112290   \n",
       "4332           0.262955           0.010117          -0.031551   \n",
       "2334           0.199453          -0.059948          -0.091760   \n",
       "1011           0.274678          -0.023188          -0.124038   \n",
       "2432           0.285042          -0.014604          -0.098389   \n",
       "5187           0.231026          -0.018501          -0.085397   \n",
       "4948           0.247617          -0.025411          -0.098561   \n",
       "\n",
       "      tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "3900         -0.975585         -0.950248         -0.983110         -0.976929   \n",
       "3249         -0.995603         -0.983865         -0.987185         -0.995962   \n",
       "3133         -0.987626         -0.992428         -0.994599         -0.987766   \n",
       "4748         -0.994860         -0.990906         -0.960534         -0.995527   \n",
       "4332          0.187343          0.199283          0.024492          0.145770   \n",
       "2334         -0.052589          0.365935          0.440688         -0.204273   \n",
       "1011         -0.986829         -0.896585         -0.949241         -0.988640   \n",
       "2432         -0.981022         -0.941819         -0.969614         -0.983827   \n",
       "5187         -0.647512         -0.226758         -0.464132         -0.684126   \n",
       "4948         -0.985436         -0.993529         -0.986809         -0.986160   \n",
       "\n",
       "      tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  \\\n",
       "3900         -0.967475         -0.985013         -0.943272   \n",
       "3249         -0.981904         -0.986120         -0.942257   \n",
       "3133         -0.992376         -0.994516         -0.944877   \n",
       "4748         -0.991223         -0.956639         -0.939066   \n",
       "4332          0.144106         -0.012666          0.532282   \n",
       "2334          0.150769          0.341375          0.450127   \n",
       "1011         -0.905424         -0.949307         -0.924255   \n",
       "2432         -0.941344         -0.970939         -0.915560   \n",
       "5187         -0.211773         -0.465463         -0.526001   \n",
       "4948         -0.992939         -0.985661         -0.938357   \n",
       "\n",
       "             ...          fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "3900         ...                                -0.625542   \n",
       "3249         ...                                -0.834985   \n",
       "3133         ...                                -0.829668   \n",
       "4748         ...                                -0.358486   \n",
       "4332         ...                                -0.400709   \n",
       "2334         ...                                -0.822773   \n",
       "1011         ...                                -0.559741   \n",
       "2432         ...                                -0.512113   \n",
       "5187         ...                                -0.302043   \n",
       "4948         ...                                -0.517001   \n",
       "\n",
       "      angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "3900                    -0.047591                              0.294363   \n",
       "3249                     0.062786                              0.116185   \n",
       "3133                    -0.009214                              0.057465   \n",
       "4748                    -0.006207                              0.065880   \n",
       "4332                     0.267329                             -0.806729   \n",
       "2334                     0.274326                             -0.703220   \n",
       "1011                     0.036589                             -0.208449   \n",
       "2432                     0.013388                              0.285030   \n",
       "5187                     0.398029                              0.035812   \n",
       "4948                    -0.034842                              0.692982   \n",
       "\n",
       "      angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "3900                          0.371649                              0.603734   \n",
       "3249                          0.539752                              0.794508   \n",
       "3133                          0.009576                             -0.550627   \n",
       "4748                          0.430711                             -0.348322   \n",
       "4332                          0.525317                             -0.547566   \n",
       "2334                          0.499672                             -0.669544   \n",
       "1011                         -0.622251                             -0.746405   \n",
       "2432                         -0.373395                             -0.199334   \n",
       "5187                          0.766658                             -0.813525   \n",
       "4948                          0.378813                              0.195420   \n",
       "\n",
       "      angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "3900              0.822001             -0.470098             -0.501469   \n",
       "3249             -0.667936              0.219258              0.219253   \n",
       "3133              0.500488              0.423776             -0.779215   \n",
       "4748             -0.876278              0.057382              0.099142   \n",
       "4332             -0.633226              0.319721              0.141660   \n",
       "2334             -0.572030              0.257497              0.272840   \n",
       "1011             -0.723051              0.275768             -0.054909   \n",
       "2432             -0.572743              0.176423              0.313674   \n",
       "5187             -0.698809              0.174313             -0.183912   \n",
       "4948              0.548939             -0.247938             -0.767568   \n",
       "\n",
       "      subject            Activity  \n",
       "3900       19              LAYING  \n",
       "3249       17            STANDING  \n",
       "3133       16              LAYING  \n",
       "4748       23             SITTING  \n",
       "4332       21  WALKING_DOWNSTAIRS  \n",
       "2334       14  WALKING_DOWNSTAIRS  \n",
       "1011        6            STANDING  \n",
       "2432       14             SITTING  \n",
       "5187       25             WALKING  \n",
       "4948       23              LAYING  \n",
       "\n",
       "[10 rows x 563 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the shapes of training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 563)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 563)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before we begin, let's shuffle our training and test datasets to avoid and elements of bias/patterns and make sure that our models remains general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=shuffle(train)\n",
    "test=shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will try to find if there are any missing or null values which can affect our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().any().any())\n",
    "print(test.isnull().any().any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no missing values in our training and test datasets, we are not required to do any data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the label columns from training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainData=train.drop('Activity',axis=1).values\n",
    "trainLabel=train.Activity.values\n",
    "\n",
    "testData=test.drop('Activity',axis=1).values\n",
    "testLabel=test.Activity.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RandomForest are very easy to tune and less prone to overfitting, we will try to build a Random Forest Classifier model to see how well it performs in terms of performance and time required for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.garysieling.com/blog/sklearn-gini-vs-entropy-criteria\n",
    "\n",
    "Link for gini vs entropy for randomforestclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken by Random Forest Classifier : 3.6924359798431396 sec\n",
      "F1-score for Random Forest Classifier : 0.924669155073\n",
      "Accuracy score for Random Forest Classifier : 0.924669155073\n",
      "Classification Report :                     precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.91      0.88      0.89       491\n",
      "          STANDING       0.89      0.92      0.90       532\n",
      "           WALKING       0.90      0.97      0.93       496\n",
      "WALKING_DOWNSTAIRS       0.96      0.85      0.90       420\n",
      "  WALKING_UPSTAIRS       0.90      0.92      0.91       471\n",
      "\n",
      "       avg / total       0.93      0.92      0.92      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "forest=RandomForestClassifier(n_estimators=100,\n",
    "                              n_jobs=-1,\n",
    "                              random_state=0)\n",
    "\n",
    "start=time.time()\n",
    "forest.fit(trainData,trainLabel)\n",
    "end=time.time()\n",
    "\n",
    "print('Time Taken by Random Forest Classifier :',(end-start),'sec')\n",
    "\n",
    "forest_prediction=forest.predict(testData)\n",
    "print(\"F1-score for Random Forest Classifier :\",f1_score(testLabel,forest_prediction,average='micro'))\n",
    "print(\"Accuracy score for Random Forest Classifier :\",accuracy_score(testLabel,forest_prediction))\n",
    "print('Classification Report :',classification_report(testLabel,forest_prediction,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier was able to give us a f1_score and accuracy score of 92%. Let's see if we can increase the scores using GradientBoosting Classifier which tries to find optimal linear combination of trees. However, since there can be many hyperparameters that can be tuned to utilize actual potential of GradientBoosting Classifier, we will employ a Grid Search to find optimal hyperparameters for GradientBoosting Classifier.             But before we step in hyperparameter tuning, let's take a look at a baseline model with default parameters and then we will proceed by tuning hyperparameters accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n",
      "\n",
      "Time Taken : 33.964617013931274 sec\n",
      "F1-score for Gradient Boosting Classifier : 0.941974889718\n",
      "Accuracy score for Gradient Boosting Classifier : 0.941974889718\n",
      "Classification Report :                     precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.93      0.89      0.91       491\n",
      "          STANDING       0.91      0.94      0.92       532\n",
      "           WALKING       0.94      0.97      0.95       496\n",
      "WALKING_DOWNSTAIRS       0.97      0.91      0.94       420\n",
      "  WALKING_UPSTAIRS       0.91      0.94      0.92       471\n",
      "\n",
      "       avg / total       0.94      0.94      0.94      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid={'learning_rate': [0.1],\n",
    "            'n_estimators':[100],\n",
    "            'max_depth': [3],\n",
    "            'min_samples_leaf': [1],\n",
    "            'max_features':['sqrt']\n",
    "           }\n",
    "\n",
    "\n",
    "grad_boost_GS_base = GridSearchCV(GradientBoostingClassifier(random_state=0),\n",
    "                                  param_grid=param_grid,\n",
    "                                  cv=5,scoring='accuracy',\n",
    "                                  verbose=1,n_jobs=-1)\n",
    "\n",
    "start=time.time()\n",
    "grad_boost_GS_base.fit(trainData,trainLabel)\n",
    "end=time.time()\n",
    "\n",
    "print('Training Complete\\n')\n",
    "print('Time Taken :',(end-start),'sec')\n",
    "\n",
    "\n",
    "grad_boost_predictions_base=grad_boost_GS_base.predict(testData)\n",
    "\n",
    "print(\"F1-score for Gradient Boosting Classifier :\",f1_score(testLabel,grad_boost_predictions_base,average='micro'))\n",
    "print(\"Accuracy score for Gradient Boosting Classifier :\",accuracy_score(testLabel,grad_boost_predictions_base))\n",
    "print('Classification Report :',classification_report(testLabel,grad_boost_predictions_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find that the baseline model for GradientBoosting Classifier has achieved an accuracy and f1-score of ~94.2%. Let's tune some hyperparameters to see if we can push our model performance even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow general approach for parameter tuning as advised in this tutorial (https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/). We first tune tree based parameters followed by boosting parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's find an optimal learning rate and optimal number of trees for corresponding learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n",
      "\n",
      "Time Taken : 186.42142868041992 sec\n",
      "F1-score for Gradient Boosting Classifier : 0.947404139803\n",
      "Accuracy score for Gradient Boosting Classifier : 0.947404139803\n",
      "Classification Report :                     precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.94      0.88      0.91       491\n",
      "          STANDING       0.90      0.94      0.92       532\n",
      "           WALKING       0.94      0.97      0.96       496\n",
      "WALKING_DOWNSTAIRS       0.98      0.92      0.95       420\n",
      "  WALKING_UPSTAIRS       0.93      0.95      0.94       471\n",
      "\n",
      "       avg / total       0.95      0.95      0.95      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid={'learning_rate': [0.1,0.2,0.3],\n",
    "            'n_estimators':[100,150,200],\n",
    "            'max_depth': [3],\n",
    "            'min_samples_leaf': [1],\n",
    "            'max_features':['sqrt']\n",
    "           }\n",
    "\n",
    "\n",
    "grad_boost_GS = GridSearchCV(GradientBoostingClassifier(random_state=0),\n",
    "                             param_grid=param_grid,\n",
    "                             cv=5,scoring='accuracy',\n",
    "                             verbose=1,n_jobs=-1)\n",
    "start=time.time()\n",
    "grad_boost_GS.fit(trainData,trainLabel)\n",
    "end=time.time()\n",
    "\n",
    "print('Training Complete\\n')\n",
    "print('Time Taken :',(end-start),'sec')\n",
    "\n",
    "\n",
    "grad_boost_predictions=grad_boost_GS.predict(testData)\n",
    "\n",
    "print(\"F1-score for Gradient Boosting Classifier :\",f1_score(testLabel,grad_boost_predictions,average='micro'))\n",
    "print(\"Accuracy score for Gradient Boosting Classifier :\",accuracy_score(testLabel,grad_boost_predictions))\n",
    "print('Classification Report :',classification_report(testLabel,grad_boost_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.2,\n",
       "  'max_depth': 3,\n",
       "  'max_features': 'sqrt',\n",
       "  'min_samples_leaf': 1,\n",
       "  'n_estimators': 150},\n",
       " 0.99265505984766045)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_GS.best_params_,grad_boost_GS.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some iterations in above step, we found 0.2 as optimal learning rate with 150 as optimal trees in this case. Also, we can observe that we were able to increase our model performance upto ~94.7% which is 2.5% higher than the baseline model. Next step is to tune some boosting parameters. We will try with tuning max_depth, num_samples_split and min_samples_leaf and see if we can see any further performance gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 19.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n",
      "\n",
      "Time Taken : 1200.3514626026154 sec\n",
      "F1-score for Gradient Boosting Classifier : 0.945707499152\n",
      "Accuracy score for Gradient Boosting Classifier : 0.945707499152\n",
      "Classification Report :                     precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.96      0.89      0.92       491\n",
      "          STANDING       0.91      0.96      0.94       532\n",
      "           WALKING       0.94      0.95      0.94       496\n",
      "WALKING_DOWNSTAIRS       0.97      0.91      0.94       420\n",
      "  WALKING_UPSTAIRS       0.90      0.94      0.92       471\n",
      "\n",
      "       avg / total       0.95      0.95      0.95      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid={'max_depth': range(3,10,3),\n",
    "            'min_samples_leaf': range(10,51,10),\n",
    "            'min_samples_split':range(100,801,200)\n",
    "           }\n",
    "\n",
    "\n",
    "grad_boost_GS = GridSearchCV(GradientBoostingClassifier(learning_rate=0.2,\n",
    "                                                        n_estimators=150,\n",
    "                                                        max_features='sqrt',\n",
    "                                                        random_state=0),\n",
    "                             param_grid=param_grid,\n",
    "                             cv=5,scoring='accuracy',\n",
    "                             verbose=1,n_jobs=-1)\n",
    "\n",
    "start=time.time()\n",
    "grad_boost_GS.fit(trainData,trainLabel)\n",
    "end=time.time()\n",
    "\n",
    "print('Training Complete\\n')\n",
    "print('Time Taken :',(end-start),'sec')\n",
    "\n",
    "\n",
    "grad_boost_predictions=grad_boost_GS.predict(testData)\n",
    "\n",
    "print(\"F1-score for Gradient Boosting Classifier :\",f1_score(testLabel,grad_boost_predictions,average='micro'))\n",
    "print(\"Accuracy score for Gradient Boosting Classifier :\",accuracy_score(testLabel,grad_boost_predictions))\n",
    "print('Classification Report :',classification_report(testLabel,grad_boost_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 9, 'min_samples_leaf': 50, 'min_samples_split': 500},\n",
       " 0.99415125136017413)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_GS.best_params_,grad_boost_GS.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The performance of the model above didn't showed improvement which can be due to overfitting of our GradientBoosting model.              \n",
    "Finally let's compare one more model with SVM to see if it can do any better than other models studied above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for Gradient Boosting Classifier : 0.963352561927\n",
      "Accuracy score for Gradient Boosting Classifier : 0.963352561927\n",
      "Classification Report :                     precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.96      0.89      0.92       491\n",
      "          STANDING       0.90      0.97      0.94       532\n",
      "           WALKING       0.95      1.00      0.97       496\n",
      "WALKING_DOWNSTAIRS       0.99      0.98      0.98       420\n",
      "  WALKING_UPSTAIRS       0.98      0.95      0.97       471\n",
      "\n",
      "       avg / total       0.96      0.96      0.96      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={'kernel':['linear','rbf'],\n",
    "           'C':[0.1,1,10]}\n",
    "\n",
    "svm_gs=GridSearchCV(SVC(random_state=0),\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,n_jobs=-1)\n",
    "\n",
    "start=time.time()\n",
    "svm_gs.fit(trainData,trainLabel)\n",
    "end=time.time()\n",
    "\n",
    "svm_gs_predictions=svm_gs.predict(testData)\n",
    "\n",
    "\n",
    "print(\"F1-score for Gradient Boosting Classifier :\",f1_score(testLabel,svm_gs_predictions,average='micro'))\n",
    "print(\"Accuracy score for Gradient Boosting Classifier :\",accuracy_score(testLabel,svm_gs_predictions))\n",
    "print('Classification Report :',classification_report(testLabel,svm_gs_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that SVM were able to perform much better than RandomForest and GradientBoosting Classifiers with accuracy and F1-score of more than 96%. The combination of linear kernel with C=1 gave best result in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
